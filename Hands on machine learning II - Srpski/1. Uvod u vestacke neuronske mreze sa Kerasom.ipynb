{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uvod u vestacke neuronske mreze sa Kerasom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000] , y_train_full[5000:] \n",
    "\n",
    "class_names = ['T-shirt/top', 'Trousers', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Anklee boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd766e5f8b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[1], cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 19:11:33.882768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 19:11:34.073850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 19:11:34.074081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 19:11:34.074610: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-22 19:11:34.074889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 19:11:34.075097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 19:11:34.075280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 19:11:35.276014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 19:11:35.276257: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 19:11:35.276428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 19:11:35.276573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2070 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 SUPER, pci bus id: 0000:10:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.flatten.Flatten at 0x7fd764d37100>,\n",
       " <keras.layers.core.dense.Dense at 0x7fd764d372b0>,\n",
       " <keras.layers.core.dense.Dense at 0x7fd764d76e30>,\n",
       " <keras.layers.core.dense.Dense at 0x7fd764d371f0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02184594, -0.02261101, -0.03673158, ...,  0.00176495,\n",
       "         0.01777706,  0.02936248],\n",
       "       [-0.0513427 ,  0.03707183,  0.07026698, ..., -0.04350982,\n",
       "         0.0474685 ,  0.00192172],\n",
       "       [-0.01404224,  0.06753987, -0.06943293, ...,  0.04758557,\n",
       "        -0.02940413,  0.01205459],\n",
       "       ...,\n",
       "       [-0.002331  , -0.01956104,  0.07180093, ...,  0.01679608,\n",
       "        -0.05816129, -0.03710493],\n",
       "       [ 0.03752202,  0.02414612, -0.04583811, ..., -0.02952005,\n",
       "        -0.00054947, -0.00365552],\n",
       "       [-0.02633374, -0.06331738, -0.06813873, ...,  0.04851275,\n",
       "         0.00736279,  0.00841624]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = model.layers[1].get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=[keras.metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 7s 3ms/step - loss: 0.7096 - sparse_categorical_accuracy: 0.7667 - val_loss: 0.5026 - val_sparse_categorical_accuracy: 0.8270\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4828 - sparse_categorical_accuracy: 0.8318 - val_loss: 0.4424 - val_sparse_categorical_accuracy: 0.8478\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4388 - sparse_categorical_accuracy: 0.8457 - val_loss: 0.4195 - val_sparse_categorical_accuracy: 0.8564\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4107 - sparse_categorical_accuracy: 0.8552 - val_loss: 0.3939 - val_sparse_categorical_accuracy: 0.8642\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3921 - sparse_categorical_accuracy: 0.8615 - val_loss: 0.3757 - val_sparse_categorical_accuracy: 0.8692\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3755 - sparse_categorical_accuracy: 0.8685 - val_loss: 0.3683 - val_sparse_categorical_accuracy: 0.8744\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3627 - sparse_categorical_accuracy: 0.8731 - val_loss: 0.3753 - val_sparse_categorical_accuracy: 0.8708\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3516 - sparse_categorical_accuracy: 0.8757 - val_loss: 0.3593 - val_sparse_categorical_accuracy: 0.8730\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3413 - sparse_categorical_accuracy: 0.8790 - val_loss: 0.3439 - val_sparse_categorical_accuracy: 0.8760\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3325 - sparse_categorical_accuracy: 0.8815 - val_loss: 0.3428 - val_sparse_categorical_accuracy: 0.8792\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3233 - sparse_categorical_accuracy: 0.8847 - val_loss: 0.3376 - val_sparse_categorical_accuracy: 0.8840\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3154 - sparse_categorical_accuracy: 0.8884 - val_loss: 0.3641 - val_sparse_categorical_accuracy: 0.8702\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3085 - sparse_categorical_accuracy: 0.8891 - val_loss: 0.3363 - val_sparse_categorical_accuracy: 0.8836\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3017 - sparse_categorical_accuracy: 0.8923 - val_loss: 0.3425 - val_sparse_categorical_accuracy: 0.8806\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2957 - sparse_categorical_accuracy: 0.8941 - val_loss: 0.3271 - val_sparse_categorical_accuracy: 0.8832\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2892 - sparse_categorical_accuracy: 0.8958 - val_loss: 0.3341 - val_sparse_categorical_accuracy: 0.8796\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2835 - sparse_categorical_accuracy: 0.8981 - val_loss: 0.3168 - val_sparse_categorical_accuracy: 0.8892\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2787 - sparse_categorical_accuracy: 0.9001 - val_loss: 0.3101 - val_sparse_categorical_accuracy: 0.8864\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2727 - sparse_categorical_accuracy: 0.9026 - val_loss: 0.3031 - val_sparse_categorical_accuracy: 0.8946\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2674 - sparse_categorical_accuracy: 0.9042 - val_loss: 0.3237 - val_sparse_categorical_accuracy: 0.8860\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2640 - sparse_categorical_accuracy: 0.9058 - val_loss: 0.3038 - val_sparse_categorical_accuracy: 0.8936\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2580 - sparse_categorical_accuracy: 0.9071 - val_loss: 0.3062 - val_sparse_categorical_accuracy: 0.8924\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2545 - sparse_categorical_accuracy: 0.9093 - val_loss: 0.3191 - val_sparse_categorical_accuracy: 0.8870\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2491 - sparse_categorical_accuracy: 0.9118 - val_loss: 0.3032 - val_sparse_categorical_accuracy: 0.8930\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2450 - sparse_categorical_accuracy: 0.9117 - val_loss: 0.3066 - val_sparse_categorical_accuracy: 0.8900\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2406 - sparse_categorical_accuracy: 0.9132 - val_loss: 0.2913 - val_sparse_categorical_accuracy: 0.8978\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2372 - sparse_categorical_accuracy: 0.9152 - val_loss: 0.3113 - val_sparse_categorical_accuracy: 0.8856\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2336 - sparse_categorical_accuracy: 0.9156 - val_loss: 0.3016 - val_sparse_categorical_accuracy: 0.8914\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2294 - sparse_categorical_accuracy: 0.9181 - val_loss: 0.3080 - val_sparse_categorical_accuracy: 0.8910\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2269 - sparse_categorical_accuracy: 0.9175 - val_loss: 0.3087 - val_sparse_categorical_accuracy: 0.8846\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2225 - sparse_categorical_accuracy: 0.9205 - val_loss: 0.2945 - val_sparse_categorical_accuracy: 0.8956\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2179 - sparse_categorical_accuracy: 0.9220 - val_loss: 0.2941 - val_sparse_categorical_accuracy: 0.8978\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2149 - sparse_categorical_accuracy: 0.9223 - val_loss: 0.3150 - val_sparse_categorical_accuracy: 0.8902\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2115 - sparse_categorical_accuracy: 0.9246 - val_loss: 0.2996 - val_sparse_categorical_accuracy: 0.8932\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2073 - sparse_categorical_accuracy: 0.9249 - val_loss: 0.3000 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2045 - sparse_categorical_accuracy: 0.9269 - val_loss: 0.3068 - val_sparse_categorical_accuracy: 0.8930\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2021 - sparse_categorical_accuracy: 0.9279 - val_loss: 0.2974 - val_sparse_categorical_accuracy: 0.8960\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1974 - sparse_categorical_accuracy: 0.9297 - val_loss: 0.3099 - val_sparse_categorical_accuracy: 0.8950\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1951 - sparse_categorical_accuracy: 0.9306 - val_loss: 0.2863 - val_sparse_categorical_accuracy: 0.8970\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1914 - sparse_categorical_accuracy: 0.9319 - val_loss: 0.2966 - val_sparse_categorical_accuracy: 0.8976\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1897 - sparse_categorical_accuracy: 0.9313 - val_loss: 0.2977 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1861 - sparse_categorical_accuracy: 0.9334 - val_loss: 0.3122 - val_sparse_categorical_accuracy: 0.8912\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1823 - sparse_categorical_accuracy: 0.9358 - val_loss: 0.2960 - val_sparse_categorical_accuracy: 0.8986\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1791 - sparse_categorical_accuracy: 0.9366 - val_loss: 0.3016 - val_sparse_categorical_accuracy: 0.8960\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1771 - sparse_categorical_accuracy: 0.9377 - val_loss: 0.3004 - val_sparse_categorical_accuracy: 0.8938\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1744 - sparse_categorical_accuracy: 0.9377 - val_loss: 0.2933 - val_sparse_categorical_accuracy: 0.8966\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1714 - sparse_categorical_accuracy: 0.9400 - val_loss: 0.3055 - val_sparse_categorical_accuracy: 0.8922\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1692 - sparse_categorical_accuracy: 0.9395 - val_loss: 0.3345 - val_sparse_categorical_accuracy: 0.8860\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1668 - sparse_categorical_accuracy: 0.9406 - val_loss: 0.2906 - val_sparse_categorical_accuracy: 0.9022\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1639 - sparse_categorical_accuracy: 0.9408 - val_loss: 0.3010 - val_sparse_categorical_accuracy: 0.8962\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1619 - sparse_categorical_accuracy: 0.9423 - val_loss: 0.2980 - val_sparse_categorical_accuracy: 0.8962\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1582 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.2870 - val_sparse_categorical_accuracy: 0.9004\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1550 - sparse_categorical_accuracy: 0.9445 - val_loss: 0.3089 - val_sparse_categorical_accuracy: 0.8974\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1534 - sparse_categorical_accuracy: 0.9458 - val_loss: 0.2922 - val_sparse_categorical_accuracy: 0.9000\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1512 - sparse_categorical_accuracy: 0.9463 - val_loss: 0.2949 - val_sparse_categorical_accuracy: 0.9018\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1481 - sparse_categorical_accuracy: 0.9471 - val_loss: 0.2995 - val_sparse_categorical_accuracy: 0.8978\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1464 - sparse_categorical_accuracy: 0.9477 - val_loss: 0.3037 - val_sparse_categorical_accuracy: 0.9012\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1448 - sparse_categorical_accuracy: 0.9486 - val_loss: 0.2962 - val_sparse_categorical_accuracy: 0.8966\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1411 - sparse_categorical_accuracy: 0.9499 - val_loss: 0.3182 - val_sparse_categorical_accuracy: 0.8918\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1390 - sparse_categorical_accuracy: 0.9506 - val_loss: 0.3055 - val_sparse_categorical_accuracy: 0.9028\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upotreba modela za izracunavanje predvidjanja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd61d0f53c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(131)\n",
    "plt.imshow(X_test[0], cmap='binary')\n",
    "plt.subplot(132)\n",
    "plt.imshow(X_test[1], cmap='binary')\n",
    "plt.subplot(133)\n",
    "plt.imshow(X_test[2], cmap='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Izrada regresionog MLP-a pomocu API-ja Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.fit_transform(X_valid)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8448 - val_loss: 0.9135\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5983 - val_loss: 0.4690\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4681 - val_loss: 0.4335\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4444 - val_loss: 0.4242\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4314 - val_loss: 0.4128\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4208 - val_loss: 0.4063\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4149 - val_loss: 0.3995\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4077 - val_loss: 0.4072\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4019 - val_loss: 0.4050\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3973 - val_loss: 0.3967\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3927 - val_loss: 0.4163\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3890 - val_loss: 0.4129\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3860 - val_loss: 0.4181\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3811 - val_loss: 0.4155\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3833 - val_loss: 0.4191\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3767 - val_loss: 0.4182\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3737 - val_loss: 0.4243\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3753 - val_loss: 0.4618\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3694 - val_loss: 0.4318\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3676 - val_loss: 0.4391\n",
      "162/162 [==============================] - 0s 2ms/step - loss: 1.3339\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "  keras.layers.Dense(30, activation=keras.activations.relu, input_shape=X_train.shape[1:]),\n",
    "  keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Izrada slozenih modela pomocu API-ja Functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 30)           270         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 30)           930         ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 38)           0           ['input_1[0][0]',                \n",
      "                                                                  'dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1)            39          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 3ms/step - loss: 2.2385 - val_loss: 0.7215\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6527 - val_loss: 0.6268\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6066 - val_loss: 0.6033\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5840 - val_loss: 0.5823\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5651 - val_loss: 0.5684\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5495 - val_loss: 0.5553\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5370 - val_loss: 0.5442\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5261 - val_loss: 0.5361\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5168 - val_loss: 0.5280\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5094 - val_loss: 0.5206\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5018 - val_loss: 0.5134\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4955 - val_loss: 0.5085\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4898 - val_loss: 0.5040\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4850 - val_loss: 0.4994\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4801 - val_loss: 0.4963\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4762 - val_loss: 0.4933\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4741 - val_loss: 0.4898\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4700 - val_loss: 0.4893\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4669 - val_loss: 0.4850\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4642 - val_loss: 0.4806\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.5254\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upotreba API-ja Subclassing za izradu dinamickih modela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    "  def __init__(self, units=30, activation='relu', **kwargs):\n",
    "    super().__init__(**kwargs)\n",
    "    self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "    self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "    self.main_output = keras.layers.Dense(1)\n",
    "    self.aux_output = keras.layers.Dense(1)\n",
    "    \n",
    "  def call(self, inputs):\n",
    "    input_A, input_B = inputs\n",
    "    hidden1 = self.hidden1(input_B)\n",
    "    hidden2 = self.hidden2(hidden1)\n",
    "    concat = keras.layers.concatenate([input_A, hidden2])\n",
    "    main_output = self.main_output(concat)\n",
    "    aux_output = self.aux_output(hidden2)\n",
    "    return main_output, aux_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upis i ucitavanje modela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 30)                270       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upotreba callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3483 - val_loss: 0.5538\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3462 - val_loss: 0.5360\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3426 - val_loss: 0.5391\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3416 - val_loss: 0.5657\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3406 - val_loss: 0.5519\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3411 - val_loss: 0.5337\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3377 - val_loss: 0.5661\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3393 - val_loss: 0.5750\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3475 - val_loss: 0.5534\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3383 - val_loss: 0.5788\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('my_keras_model.h5', save_best_only=True)\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    epochs=10, callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upotreba TensorBoarda za vizuelizaciju"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "root_logdir = '../keras/logs'\n",
    "\n",
    "def get_run_logdir():\n",
    "  import time\n",
    "  run_id = time.strftime('run%Y%m_%d-%H%M%S')\n",
    "  return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3342 - val_loss: 0.5762\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3325 - val_loss: 0.5783\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3307 - val_loss: 0.5980\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3472 - val_loss: 0.6469\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3318 - val_loss: 0.6348\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3288 - val_loss: 0.6043\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3300 - val_loss: 0.6205\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3256 - val_loss: 0.6210\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3257 - val_loss: 0.6560\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3276 - val_loss: 0.6930\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "histroy = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    epochs=10, callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9995), started 0:00:32 ago. (Use '!kill 9995' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b11b4e30d3e8f0a5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b11b4e30d3e8f0a5\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=../keras/logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_logdir = get_run_logdir()\n",
    "writer = tf.summary.create_file_writer(test_logdir)\n",
    "with writer.as_default():\n",
    "  for step in range(1, 1000 + 1):\n",
    "    tf.summary.scalar('my_scalar', np.sin(step / 10), step=step)\n",
    "    data = (np.random.randn(100) + 2) * step / 100\n",
    "    tf.summary.histogram('my_hist', data, buckets=50, step=step)\n",
    "    images = np.random.randn(2, 32, 32, 3)\n",
    "    tf.summary.image('my_images', images * step / 1000, step=step),\n",
    "    texts = ['Korak je' + str(step), 'Kvadrat je ' + str(step**2)]\n",
    "    tf.summary.text('my_text', texts, step=step)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fino podesavanje hiperparametra neuronskih mreza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, lr=3e-3, input_shape=[8]):\n",
    "  model = keras.models.Sequential()\n",
    "  model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "  for layer in range(n_hidden):\n",
    "    model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "  model.add(keras.layers.Dense(1))\n",
    "  optimizer = keras.optimizers.SGD(lr=lr)\n",
    "  model.compile(loss='mse', optimizer=optimizer)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5287/1709004121.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
     ]
    }
   ],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 3ms/step - loss: 1.0863 - val_loss: 0.6877\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6351 - val_loss: 0.5805\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5570 - val_loss: 0.5333\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5260 - val_loss: 0.4998\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4945 - val_loss: 0.4826\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4784 - val_loss: 0.4752\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4872 - val_loss: 0.4598\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4588 - val_loss: 0.4496\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4541 - val_loss: 0.4432\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4459 - val_loss: 0.4401\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4405 - val_loss: 0.4364\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4374 - val_loss: 0.4304\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4320 - val_loss: 0.4234\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4296 - val_loss: 0.4355\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4295 - val_loss: 0.4367\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4277 - val_loss: 0.4181\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4252 - val_loss: 0.4161\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4190 - val_loss: 0.4123\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4175 - val_loss: 0.4064\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4164 - val_loss: 0.4093\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4133 - val_loss: 0.4024\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4118 - val_loss: 0.4025\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4108 - val_loss: 0.3973\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4089 - val_loss: 0.3977\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4071 - val_loss: 0.3963\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4045 - val_loss: 0.3971\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4039 - val_loss: 0.3954\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4017 - val_loss: 0.4042\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4015 - val_loss: 0.3935\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3999 - val_loss: 0.3926\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3984 - val_loss: 0.3877\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3965 - val_loss: 0.3878\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3945 - val_loss: 0.3894\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4002 - val_loss: 0.3872\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3917 - val_loss: 0.3825\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3900 - val_loss: 0.3885\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3907 - val_loss: 0.3824\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3878 - val_loss: 0.3829\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3868 - val_loss: 0.3835\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3851 - val_loss: 0.3813\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3840 - val_loss: 0.3847\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3830 - val_loss: 0.3918\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3831 - val_loss: 0.3836\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3808 - val_loss: 0.3832\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3795 - val_loss: 0.3806\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3785 - val_loss: 0.3856\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3772 - val_loss: 0.3822\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3769 - val_loss: 0.3854\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3760 - val_loss: 0.3840\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3738 - val_loss: 0.3869\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3742 - val_loss: 0.3830\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3722 - val_loss: 0.3887\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3708 - val_loss: 0.3923\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3705 - val_loss: 0.3876\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3695 - val_loss: 0.3916\n",
      "162/162 [==============================] - 0s 3ms/step - loss: 0.8377\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "              validation_data=(X_valid, y_valid),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "  'n_hidden': [0, 1, 2, 3, 4],\n",
    "  'n_neurons': np.arange(1, 100),\n",
    "  'lr': reciprocal(3e-4, 3e-2)\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 4ms/step - loss: 1.3775 - val_loss: 0.6127\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5710 - val_loss: 0.5389\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5217 - val_loss: 0.4615\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4627 - val_loss: 0.4224\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4336 - val_loss: 0.4065\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4161 - val_loss: 0.3863\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4034 - val_loss: 0.3911\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3946 - val_loss: 0.3799\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3866 - val_loss: 0.3813\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3788 - val_loss: 0.3773\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3717 - val_loss: 0.4040\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3646 - val_loss: 0.3787\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3579 - val_loss: 0.3818\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3556 - val_loss: 0.3859\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3482 - val_loss: 0.3949\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3438 - val_loss: 0.4177\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3402 - val_loss: 0.4013\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3360 - val_loss: 0.4537\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3329 - val_loss: 0.4468\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3292 - val_loss: 0.4607\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3226\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0329 - val_loss: 0.5689\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5153 - val_loss: 0.4770\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4550 - val_loss: 0.4540\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4230 - val_loss: 0.4153\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4039 - val_loss: 0.4003\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3916 - val_loss: 0.3958\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3847 - val_loss: 0.3916\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3749 - val_loss: 0.3894\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3696 - val_loss: 0.3922\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3631 - val_loss: 0.3883\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3579 - val_loss: 0.3865\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3534 - val_loss: 0.3947\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3469 - val_loss: 0.3952\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3440 - val_loss: 0.3933\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3372 - val_loss: 0.4070\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3353 - val_loss: 0.3949\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3314 - val_loss: 0.4019\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3300 - val_loss: 0.4318\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3251 - val_loss: 0.4278\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3232 - val_loss: 0.4679\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3183 - val_loss: 0.4666\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3571\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0855 - val_loss: 0.6167\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5494 - val_loss: 0.5299\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4742 - val_loss: 0.4831\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4462 - val_loss: 0.4492\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4285 - val_loss: 0.4341\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4167 - val_loss: 0.4332\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4060 - val_loss: 0.4060\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3975 - val_loss: 0.3958\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3899 - val_loss: 0.3898\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3840 - val_loss: 0.3825\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3796 - val_loss: 0.4184\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3734 - val_loss: 0.3771\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3693 - val_loss: 0.3862\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3632 - val_loss: 0.3709\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3570 - val_loss: 0.3864\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3553 - val_loss: 0.3812\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3509 - val_loss: 0.3956\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3472 - val_loss: 0.4294\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3421 - val_loss: 0.3933\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3383 - val_loss: 0.3853\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3346 - val_loss: 0.4000\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3335 - val_loss: 0.3994\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3273 - val_loss: 0.4293\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3280 - val_loss: 0.4319\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3237\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 2.5336 - val_loss: 4.8608\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 46.6118 - val_loss: 105.5582\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1382.9890 - val_loss: 2869.1877\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 39442.3320 - val_loss: 81922.1016\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1132896.1250 - val_loss: 2582242.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2007240.0000 - val_loss: 70970160.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 995464064.0000 - val_loss: 2334648576.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 30703294464.0000 - val_loss: 58502725632.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 794747469824.0000 - val_loss: 1726447222784.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1163668488192.0000 - val_loss: 49094043107328.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 731879808434176.0000 - val_loss: 1399845805883392.0000\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 701183475843072.0000\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3203 - val_loss: 16.8779\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 373.1354 - val_loss: 829.3146\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 21790.0156 - val_loss: 138102.9844\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3636208.0000 - val_loss: 7267743.0000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 189220576.0000 - val_loss: 387546272.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 454677184.0000 - val_loss: 19240716288.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 472743608320.0000 - val_loss: 1064428503040.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 45099568332800.0000 - val_loss: 50940207955968.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 70144676069376.0000 - val_loss: 2569167295217664.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 19935885273333760.0000 - val_loss: 133544440336744448.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3421499315976142848.0000 - val_loss: 6808999533398196224.0000\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 56283265786445824.0000\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8698 - val_loss: 0.6964\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5492 - val_loss: 0.6588\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5860 - val_loss: 0.8702\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5831 - val_loss: 0.8279\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6295 - val_loss: 1.4384\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6410 - val_loss: 1.3257\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7685 - val_loss: 2.1020\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8426 - val_loss: 2.5050\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1204 - val_loss: 3.6604\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1796 - val_loss: 4.8513\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.6391 - val_loss: 8.5394\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.2277 - val_loss: 11.5946\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 28.2728\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8175 - val_loss: 0.5895\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5457 - val_loss: 0.5074\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4887 - val_loss: 0.4856\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4766 - val_loss: 0.5067\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5737 - val_loss: 0.4451\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4500 - val_loss: 0.4268\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4346 - val_loss: 0.4115\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4317 - val_loss: 0.4181\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4243 - val_loss: 0.4010\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4160 - val_loss: 0.4141\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4163 - val_loss: 0.4231\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4132 - val_loss: 0.4154\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4116 - val_loss: 0.4007\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4012 - val_loss: 0.4139\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3981 - val_loss: 0.4186\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3990 - val_loss: 0.4195\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4119 - val_loss: 0.4055\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4026 - val_loss: 0.4003\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3943 - val_loss: 0.4087\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3850 - val_loss: 0.4190\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3891 - val_loss: 0.4121\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3819 - val_loss: 0.4175\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3809 - val_loss: 0.4167\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3775 - val_loss: 0.4227\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3867 - val_loss: 0.5285\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3771 - val_loss: 0.4620\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3826 - val_loss: 0.4554\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4144 - val_loss: 0.4557\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3566\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3474 - val_loss: 0.9063\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5478 - val_loss: 0.5270\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4304 - val_loss: 0.4872\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4026 - val_loss: 0.5133\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3887 - val_loss: 0.5467\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3816 - val_loss: 0.5664\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3701 - val_loss: 0.5693\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3646 - val_loss: 0.5785\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3594 - val_loss: 0.5769\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3551 - val_loss: 0.5817\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3505 - val_loss: 0.6501\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3488 - val_loss: 0.6795\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3460 - val_loss: 0.6244\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3838\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8937 - val_loss: 0.7958\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6325 - val_loss: 1.1723\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6582 - val_loss: 0.4971\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4680 - val_loss: 0.4402\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4480 - val_loss: 0.4312\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4382 - val_loss: 0.4184\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4299 - val_loss: 0.4082\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4281 - val_loss: 0.4120\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4176 - val_loss: 0.4024\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4117 - val_loss: 0.3970\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4091 - val_loss: 0.3957\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4042 - val_loss: 0.3976\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3998 - val_loss: 0.3958\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4150 - val_loss: 0.3941\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4035 - val_loss: 0.4007\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3966 - val_loss: 0.4131\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3897 - val_loss: 0.4117\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3918 - val_loss: 0.4042\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3837 - val_loss: 0.4087\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3842 - val_loss: 0.4137\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3805 - val_loss: 0.4135\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3791 - val_loss: 0.4440\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3954 - val_loss: 0.4230\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3751 - val_loss: 0.4307\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3620\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0866 - val_loss: 0.5811\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5307 - val_loss: 0.4935\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4723 - val_loss: 0.4561\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4442 - val_loss: 0.4320\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4280 - val_loss: 0.4159\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4142 - val_loss: 0.3956\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4065 - val_loss: 0.3906\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3977 - val_loss: 0.3799\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3911 - val_loss: 0.3725\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3841 - val_loss: 0.3814\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3792 - val_loss: 0.3744\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3736 - val_loss: 0.3654\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3706 - val_loss: 0.3706\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3636 - val_loss: 0.3694\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3613 - val_loss: 0.3905\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3583 - val_loss: 0.3729\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3556 - val_loss: 0.3799\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3473 - val_loss: 0.3913\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3440 - val_loss: 0.3873\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3430 - val_loss: 0.3979\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3368 - val_loss: 0.3933\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3333 - val_loss: 0.3977\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3383\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.4134 - val_loss: 0.5832\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5480 - val_loss: 0.4822\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4683 - val_loss: 0.4373\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4313 - val_loss: 0.4110\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4079 - val_loss: 0.3999\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3939 - val_loss: 0.4017\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3844 - val_loss: 0.3945\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3744 - val_loss: 0.3857\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3689 - val_loss: 0.3824\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3630 - val_loss: 0.3831\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3581 - val_loss: 0.3828\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3539 - val_loss: 0.3744\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3504 - val_loss: 0.3852\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3472 - val_loss: 0.3769\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3437 - val_loss: 0.3892\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3396 - val_loss: 0.3884\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3368 - val_loss: 0.4126\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3332 - val_loss: 0.4093\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3297 - val_loss: 0.4127\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3262 - val_loss: 0.4062\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3239 - val_loss: 0.4233\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3187 - val_loss: 0.5027\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3974\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 4ms/step - loss: 1.1934 - val_loss: 0.6317\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6242 - val_loss: 0.5692\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5601 - val_loss: 0.5207\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5109 - val_loss: 0.4940\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4770 - val_loss: 0.4761\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4547 - val_loss: 0.4582\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4376 - val_loss: 0.4370\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4257 - val_loss: 0.4292\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4176 - val_loss: 0.4170\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4088 - val_loss: 0.4172\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4016 - val_loss: 0.3992\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3954 - val_loss: 0.4028\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3927 - val_loss: 0.3903\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3870 - val_loss: 0.3857\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3833 - val_loss: 0.3847\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3783 - val_loss: 0.3799\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3735 - val_loss: 0.3748\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3704 - val_loss: 0.3832\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3674 - val_loss: 0.3748\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3625 - val_loss: 0.3805\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3607 - val_loss: 0.3776\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3563 - val_loss: 0.4099\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3536 - val_loss: 0.3795\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3505 - val_loss: 0.3826\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3473 - val_loss: 0.4013\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3442 - val_loss: 0.3824\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3412 - val_loss: 0.4073\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3390 - val_loss: 0.4085\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3364 - val_loss: 0.4303\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3448\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 5ms/step - loss: 1.5403 - val_loss: 0.6938\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6410 - val_loss: 0.5839\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5593 - val_loss: 0.5258\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5083 - val_loss: 0.4856\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4758 - val_loss: 0.4575\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4553 - val_loss: 0.4408\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4399 - val_loss: 0.4242\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4274 - val_loss: 0.4139\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4182 - val_loss: 0.4117\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4103 - val_loss: 0.3995\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4041 - val_loss: 0.3935\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3966 - val_loss: 0.3856\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3920 - val_loss: 0.3849\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3863 - val_loss: 0.3766\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3818 - val_loss: 0.3758\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3771 - val_loss: 0.3768\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3728 - val_loss: 0.3696\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3694 - val_loss: 0.3733\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3656 - val_loss: 0.3733\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3624 - val_loss: 0.3712\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3588 - val_loss: 0.3740\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3556 - val_loss: 0.3752\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3521 - val_loss: 0.3752\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3490 - val_loss: 0.3751\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3461 - val_loss: 0.3804\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3443 - val_loss: 0.3886\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3416 - val_loss: 0.3815\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3357\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.2847 - val_loss: 0.6250\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5805 - val_loss: 0.5523\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5162 - val_loss: 0.4958\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4699 - val_loss: 0.4644\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4404 - val_loss: 0.4361\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4199 - val_loss: 0.4288\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4077 - val_loss: 0.4114\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3966 - val_loss: 0.4101\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3892 - val_loss: 0.3961\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3827 - val_loss: 0.3959\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3761 - val_loss: 0.3874\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3710 - val_loss: 0.3887\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3679 - val_loss: 0.3796\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3641 - val_loss: 0.3783\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3591 - val_loss: 0.3759\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3560 - val_loss: 0.3760\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3508 - val_loss: 0.3743\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3491 - val_loss: 0.3864\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3450 - val_loss: 0.3760\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3423 - val_loss: 0.3730\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3399 - val_loss: 0.3828\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3367 - val_loss: 0.3734\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3339 - val_loss: 0.3766\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3300 - val_loss: 0.3798\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3274 - val_loss: 0.3867\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3249 - val_loss: 0.3805\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3208 - val_loss: 0.3846\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3188 - val_loss: 0.4130\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3179 - val_loss: 0.4078\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3151 - val_loss: 0.3934\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 0.3655\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3424 - val_loss: 0.6724\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6437 - val_loss: 0.5910\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5667 - val_loss: 0.5314\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5105 - val_loss: 0.4887\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4724 - val_loss: 0.4605\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4478 - val_loss: 0.4420\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4312 - val_loss: 0.4257\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4197 - val_loss: 0.4186\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4108 - val_loss: 0.4080\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4051 - val_loss: 0.3969\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3988 - val_loss: 0.3914\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3934 - val_loss: 0.3921\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3882 - val_loss: 0.3812\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.3840 - val_loss: 0.3778\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3817 - val_loss: 0.3798\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3770 - val_loss: 0.3733\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3736 - val_loss: 0.3714\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3698 - val_loss: 0.3716\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3664 - val_loss: 0.3663\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3628 - val_loss: 0.3614\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3600 - val_loss: 0.3627\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3558 - val_loss: 0.3630\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3543 - val_loss: 0.3631\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3509 - val_loss: 0.3645\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3471 - val_loss: 0.3902\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3463 - val_loss: 0.3675\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3418 - val_loss: 0.3683\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3390 - val_loss: 0.3746\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3371 - val_loss: 0.3807\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3349 - val_loss: 0.3799\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.3346\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 4.0074 - val_loss: 2.3157\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.6611 - val_loss: 1.1874\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9847 - val_loss: 0.8388\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7653 - val_loss: 0.7212\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6861 - val_loss: 0.6763\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6528 - val_loss: 0.6556\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6352 - val_loss: 0.6435\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6235 - val_loss: 0.6343\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6142 - val_loss: 0.6261\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6061 - val_loss: 0.6191\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5988 - val_loss: 0.6127\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5923 - val_loss: 0.6065\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5863 - val_loss: 0.6014\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5808 - val_loss: 0.5958\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5758 - val_loss: 0.5913\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5712 - val_loss: 0.5867\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5670 - val_loss: 0.5830\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5631 - val_loss: 0.5792\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5595 - val_loss: 0.5758\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5563 - val_loss: 0.5730\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5531 - val_loss: 0.5697\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5504 - val_loss: 0.5671\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5478 - val_loss: 0.5648\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5453 - val_loss: 0.5624\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5431 - val_loss: 0.5602\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5410 - val_loss: 0.5577\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5391 - val_loss: 0.5558\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5372 - val_loss: 0.5539\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5355 - val_loss: 0.5520\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5340 - val_loss: 0.5501\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5326 - val_loss: 0.5487\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5312 - val_loss: 0.5476\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5299 - val_loss: 0.5460\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5287 - val_loss: 0.5450\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5276 - val_loss: 0.5437\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5266 - val_loss: 0.5423\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5256 - val_loss: 0.5416\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5248 - val_loss: 0.5406\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5239 - val_loss: 0.5394\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5230 - val_loss: 0.5384\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5224 - val_loss: 0.5380\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5217 - val_loss: 0.5372\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5210 - val_loss: 0.5361\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5204 - val_loss: 0.5356\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5198 - val_loss: 0.5350\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5192 - val_loss: 0.5346\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5187 - val_loss: 0.5336\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5183 - val_loss: 0.5332\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5179 - val_loss: 0.5327\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5173 - val_loss: 0.5317\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5170 - val_loss: 0.5316\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5166 - val_loss: 0.5310\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5163 - val_loss: 0.5306\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5159 - val_loss: 0.5304\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5155 - val_loss: 0.5302\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5153 - val_loss: 0.5295\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5150 - val_loss: 0.5294\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5147 - val_loss: 0.5289\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5145 - val_loss: 0.5282\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5143 - val_loss: 0.5283\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5140 - val_loss: 0.5279\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5139 - val_loss: 0.5275\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5136 - val_loss: 0.5272\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5135 - val_loss: 0.5271\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5132 - val_loss: 0.5273\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5131 - val_loss: 0.5268\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5130 - val_loss: 0.5264\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5128 - val_loss: 0.5261\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5126 - val_loss: 0.5260\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5125 - val_loss: 0.5260\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5123 - val_loss: 0.5255\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5123 - val_loss: 0.5255\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5121 - val_loss: 0.5251\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5120 - val_loss: 0.5249\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5119 - val_loss: 0.5247\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5119 - val_loss: 0.5248\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5118 - val_loss: 0.5247\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5117 - val_loss: 0.5244\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5117 - val_loss: 0.5247\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5115 - val_loss: 0.5239\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5115 - val_loss: 0.5240\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5114 - val_loss: 0.5240\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5113 - val_loss: 0.5238\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5113 - val_loss: 0.5241\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5112 - val_loss: 0.5237\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5111 - val_loss: 0.5234\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5111 - val_loss: 0.5231\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5111 - val_loss: 0.5232\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5110 - val_loss: 0.5231\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5110 - val_loss: 0.5235\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5109 - val_loss: 0.5230\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5109 - val_loss: 0.5230\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5109 - val_loss: 0.5229\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5108 - val_loss: 0.5228\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5107 - val_loss: 0.5230\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5107 - val_loss: 0.5230\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5107 - val_loss: 0.5227\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5106 - val_loss: 0.5222\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5106 - val_loss: 0.5223\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5106 - val_loss: 0.5223\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.5011\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 4.1301 - val_loss: 2.5355\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.7890 - val_loss: 1.3034\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0644 - val_loss: 0.8937\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8167 - val_loss: 0.7464\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7218 - val_loss: 0.6859\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6776 - val_loss: 0.6559\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6513 - val_loss: 0.6368\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6323 - val_loss: 0.6231\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6169 - val_loss: 0.6119\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6037 - val_loss: 0.6021\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5920 - val_loss: 0.5938\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5817 - val_loss: 0.5864\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5725 - val_loss: 0.5796\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5643 - val_loss: 0.5738\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5570 - val_loss: 0.5683\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5504 - val_loss: 0.5635\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5445 - val_loss: 0.5593\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5393 - val_loss: 0.5557\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5346 - val_loss: 0.5523\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5304 - val_loss: 0.5495\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5267 - val_loss: 0.5467\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5233 - val_loss: 0.5443\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5203 - val_loss: 0.5422\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5176 - val_loss: 0.5402\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5152 - val_loss: 0.5386\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5130 - val_loss: 0.5370\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5111 - val_loss: 0.5355\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5093 - val_loss: 0.5342\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5077 - val_loss: 0.5330\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5063 - val_loss: 0.5321\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5051 - val_loss: 0.5313\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5040 - val_loss: 0.5305\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5029 - val_loss: 0.5298\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5020 - val_loss: 0.5292\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5012 - val_loss: 0.5282\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5004 - val_loss: 0.5275\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4997 - val_loss: 0.5273\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4991 - val_loss: 0.5270\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4986 - val_loss: 0.5267\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4981 - val_loss: 0.5262\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4977 - val_loss: 0.5259\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4972 - val_loss: 0.5257\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4969 - val_loss: 0.5254\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4966 - val_loss: 0.5251\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4963 - val_loss: 0.5249\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4959 - val_loss: 0.5246\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4957 - val_loss: 0.5243\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4955 - val_loss: 0.5243\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4953 - val_loss: 0.5244\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4951 - val_loss: 0.5243\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4949 - val_loss: 0.5241\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4948 - val_loss: 0.5238\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4946 - val_loss: 0.5237\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4945 - val_loss: 0.5235\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4944 - val_loss: 0.5236\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4942 - val_loss: 0.5236\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4941 - val_loss: 0.5236\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4940 - val_loss: 0.5236\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4940 - val_loss: 0.5235\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4939 - val_loss: 0.5234\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4938 - val_loss: 0.5230\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4938 - val_loss: 0.5227\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4937 - val_loss: 0.5228\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4936 - val_loss: 0.5229\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4936 - val_loss: 0.5228\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4935 - val_loss: 0.5226\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4935 - val_loss: 0.5226\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4935 - val_loss: 0.5226\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4934 - val_loss: 0.5227\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4934 - val_loss: 0.5226\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4934 - val_loss: 0.5224\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4933 - val_loss: 0.5224\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4933 - val_loss: 0.5223\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4933 - val_loss: 0.5225\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4933 - val_loss: 0.5225\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4932 - val_loss: 0.5224\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4931 - val_loss: 0.5224\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4932 - val_loss: 0.5224\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4931 - val_loss: 0.5222\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4932 - val_loss: 0.5223\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4931 - val_loss: 0.5223\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4931 - val_loss: 0.5221\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4930 - val_loss: 0.5222\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4931 - val_loss: 0.5221\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4931 - val_loss: 0.5224\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4930 - val_loss: 0.5223\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4931 - val_loss: 0.5220\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4930 - val_loss: 0.5224\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4930 - val_loss: 0.5221\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4930 - val_loss: 0.5222\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4931 - val_loss: 0.5222\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4930 - val_loss: 0.5220\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4930 - val_loss: 0.5222\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4930 - val_loss: 0.5223\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4929 - val_loss: 0.5223\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4930 - val_loss: 0.5222\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4930 - val_loss: 0.5219\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4929 - val_loss: 0.5217\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4930 - val_loss: 0.5220\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4929 - val_loss: 0.5217\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5353\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 4.3749 - val_loss: 2.6712\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.8963 - val_loss: 1.3575\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1146 - val_loss: 0.9184\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8446 - val_loss: 0.7557\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7400 - val_loss: 0.6874\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6916 - val_loss: 0.6526\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6637 - val_loss: 0.6308\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6442 - val_loss: 0.6147\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6288 - val_loss: 0.6021\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6159 - val_loss: 0.5914\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6048 - val_loss: 0.5825\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5950 - val_loss: 0.5750\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5865 - val_loss: 0.5682\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5788 - val_loss: 0.5625\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5721 - val_loss: 0.5575\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5661 - val_loss: 0.5532\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5609 - val_loss: 0.5493\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5562 - val_loss: 0.5459\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5520 - val_loss: 0.5430\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5483 - val_loss: 0.5403\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5450 - val_loss: 0.5383\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5421 - val_loss: 0.5363\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5395 - val_loss: 0.5346\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5372 - val_loss: 0.5332\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5351 - val_loss: 0.5316\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5332 - val_loss: 0.5304\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5316 - val_loss: 0.5294\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5301 - val_loss: 0.5283\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5289 - val_loss: 0.5275\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5276 - val_loss: 0.5268\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5266 - val_loss: 0.5265\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5257 - val_loss: 0.5259\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5248 - val_loss: 0.5252\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5240 - val_loss: 0.5244\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5235 - val_loss: 0.5242\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5228 - val_loss: 0.5237\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5223 - val_loss: 0.5235\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5217 - val_loss: 0.5232\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5214 - val_loss: 0.5231\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5210 - val_loss: 0.5228\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5206 - val_loss: 0.5229\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5202 - val_loss: 0.5225\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5200 - val_loss: 0.5222\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5198 - val_loss: 0.5222\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5195 - val_loss: 0.5221\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5194 - val_loss: 0.5224\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5192 - val_loss: 0.5222\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5190 - val_loss: 0.5220\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5188 - val_loss: 0.5222\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5187 - val_loss: 0.5222\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5186 - val_loss: 0.5222\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5185 - val_loss: 0.5219\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5184 - val_loss: 0.5217\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5183 - val_loss: 0.5219\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5181 - val_loss: 0.5215\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5181 - val_loss: 0.5217\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5179 - val_loss: 0.5217\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5179 - val_loss: 0.5220\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5177 - val_loss: 0.5214\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5178 - val_loss: 0.5211\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5176 - val_loss: 0.5217\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5177 - val_loss: 0.5218\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5178 - val_loss: 0.5217\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5176 - val_loss: 0.5211\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5176 - val_loss: 0.5215\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5175 - val_loss: 0.5212\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5176 - val_loss: 0.5212\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5175 - val_loss: 0.5214\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5175 - val_loss: 0.5219\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5175 - val_loss: 0.5216\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.4898\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 6.0447 - val_loss: 4.8618\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 4.1910 - val_loss: 3.4399\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.9984 - val_loss: 2.5104\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.2185 - val_loss: 1.8976\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.7051 - val_loss: 1.4874\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.3623 - val_loss: 1.2113\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1315 - val_loss: 1.0232\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9743 - val_loss: 0.8942\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8663 - val_loss: 0.8047\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7913 - val_loss: 0.7421\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7385 - val_loss: 0.6976\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7006 - val_loss: 0.6657\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6732 - val_loss: 0.6424\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6527 - val_loss: 0.6250\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6372 - val_loss: 0.6119\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6252 - val_loss: 0.6017\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6156 - val_loss: 0.5937\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6078 - val_loss: 0.5872\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6013 - val_loss: 0.5819\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5957 - val_loss: 0.5773\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5908 - val_loss: 0.5735\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5864 - val_loss: 0.5700\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5825 - val_loss: 0.5671\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5789 - val_loss: 0.5643\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5756 - val_loss: 0.5619\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5725 - val_loss: 0.5596\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5696 - val_loss: 0.5575\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5669 - val_loss: 0.5556\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5643 - val_loss: 0.5538\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5619 - val_loss: 0.5521\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5596 - val_loss: 0.5505\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5574 - val_loss: 0.5489\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5553 - val_loss: 0.5475\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5533 - val_loss: 0.5462\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5514 - val_loss: 0.5449\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5496 - val_loss: 0.5437\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5478 - val_loss: 0.5425\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5462 - val_loss: 0.5414\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5446 - val_loss: 0.5404\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5431 - val_loss: 0.5394\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5416 - val_loss: 0.5384\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5403 - val_loss: 0.5375\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5389 - val_loss: 0.5367\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5377 - val_loss: 0.5359\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5365 - val_loss: 0.5352\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5353 - val_loss: 0.5344\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5342 - val_loss: 0.5337\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5332 - val_loss: 0.5331\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5321 - val_loss: 0.5324\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5312 - val_loss: 0.5318\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5302 - val_loss: 0.5312\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5294 - val_loss: 0.5307\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5285 - val_loss: 0.5302\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5277 - val_loss: 0.5297\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5269 - val_loss: 0.5292\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5262 - val_loss: 0.5288\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5255 - val_loss: 0.5284\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.5248 - val_loss: 0.5280\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5242 - val_loss: 0.5276\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5235 - val_loss: 0.5272\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5229 - val_loss: 0.5269\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5224 - val_loss: 0.5265\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5218 - val_loss: 0.5262\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5213 - val_loss: 0.5259\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5208 - val_loss: 0.5256\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5203 - val_loss: 0.5254\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5199 - val_loss: 0.5251\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5195 - val_loss: 0.5249\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5190 - val_loss: 0.5247\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5187 - val_loss: 0.5244\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5183 - val_loss: 0.5242\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5179 - val_loss: 0.5240\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5175 - val_loss: 0.5238\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5172 - val_loss: 0.5237\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5169 - val_loss: 0.5235\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5166 - val_loss: 0.5234\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5163 - val_loss: 0.5232\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5160 - val_loss: 0.5230\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5158 - val_loss: 0.5229\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5155 - val_loss: 0.5228\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5153 - val_loss: 0.5226\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5150 - val_loss: 0.5225\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5148 - val_loss: 0.5224\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5146 - val_loss: 0.5224\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5144 - val_loss: 0.5223\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5142 - val_loss: 0.5222\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5140 - val_loss: 0.5221\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5138 - val_loss: 0.5220\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5137 - val_loss: 0.5219\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5135 - val_loss: 0.5218\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5133 - val_loss: 0.5218\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5132 - val_loss: 0.5217\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5130 - val_loss: 0.5216\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5129 - val_loss: 0.5216\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5128 - val_loss: 0.5215\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5126 - val_loss: 0.5214\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5125 - val_loss: 0.5214\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5124 - val_loss: 0.5214\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5123 - val_loss: 0.5213\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5122 - val_loss: 0.5213\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.5031\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 6.9948 - val_loss: 5.8800\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.7238 - val_loss: 4.0521\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.3093 - val_loss: 2.8953\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.4099 - val_loss: 2.1498\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.8294 - val_loss: 1.6614\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.4492 - val_loss: 1.3377\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1977 - val_loss: 1.1211\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0294 - val_loss: 0.9743\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9153 - val_loss: 0.8737\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8369 - val_loss: 0.8038\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7823 - val_loss: 0.7548\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7435 - val_loss: 0.7198\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7153 - val_loss: 0.6944\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6942 - val_loss: 0.6754\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6779 - val_loss: 0.6609\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6649 - val_loss: 0.6494\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6541 - val_loss: 0.6401\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6450 - val_loss: 0.6324\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6371 - val_loss: 0.6259\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6300 - val_loss: 0.6201\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6236 - val_loss: 0.6150\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6177 - val_loss: 0.6104\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6122 - val_loss: 0.6062\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6070 - val_loss: 0.6024\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6021 - val_loss: 0.5988\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5975 - val_loss: 0.5953\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5931 - val_loss: 0.5921\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5889 - val_loss: 0.5891\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5849 - val_loss: 0.5862\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5811 - val_loss: 0.5834\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5775 - val_loss: 0.5808\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5740 - val_loss: 0.5784\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5706 - val_loss: 0.5760\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5674 - val_loss: 0.5737\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5644 - val_loss: 0.5715\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5614 - val_loss: 0.5694\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5586 - val_loss: 0.5674\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5559 - val_loss: 0.5655\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5533 - val_loss: 0.5636\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5509 - val_loss: 0.5619\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5485 - val_loss: 0.5602\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5462 - val_loss: 0.5586\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5440 - val_loss: 0.5571\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5420 - val_loss: 0.5556\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5400 - val_loss: 0.5542\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5380 - val_loss: 0.5528\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5362 - val_loss: 0.5515\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5344 - val_loss: 0.5503\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5328 - val_loss: 0.5491\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5311 - val_loss: 0.5480\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5296 - val_loss: 0.5469\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5281 - val_loss: 0.5458\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5267 - val_loss: 0.5448\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5253 - val_loss: 0.5439\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5240 - val_loss: 0.5430\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5227 - val_loss: 0.5421\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5215 - val_loss: 0.5412\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5204 - val_loss: 0.5404\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5192 - val_loss: 0.5396\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5182 - val_loss: 0.5389\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5172 - val_loss: 0.5382\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5162 - val_loss: 0.5375\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5153 - val_loss: 0.5369\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5144 - val_loss: 0.5362\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5135 - val_loss: 0.5356\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5127 - val_loss: 0.5351\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5119 - val_loss: 0.5346\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5111 - val_loss: 0.5340\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5104 - val_loss: 0.5336\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5097 - val_loss: 0.5331\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5090 - val_loss: 0.5326\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5084 - val_loss: 0.5322\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5077 - val_loss: 0.5317\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5071 - val_loss: 0.5313\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5066 - val_loss: 0.5309\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5060 - val_loss: 0.5306\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5055 - val_loss: 0.5302\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5050 - val_loss: 0.5299\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5045 - val_loss: 0.5296\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5041 - val_loss: 0.5293\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5036 - val_loss: 0.5289\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5032 - val_loss: 0.5286\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5028 - val_loss: 0.5284\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5024 - val_loss: 0.5281\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5020 - val_loss: 0.5278\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5017 - val_loss: 0.5276\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5013 - val_loss: 0.5274\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5010 - val_loss: 0.5272\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5007 - val_loss: 0.5270\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5003 - val_loss: 0.5268\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5000 - val_loss: 0.5265\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4998 - val_loss: 0.5264\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4995 - val_loss: 0.5262\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4992 - val_loss: 0.5260\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4990 - val_loss: 0.5259\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4988 - val_loss: 0.5258\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4985 - val_loss: 0.5256\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4983 - val_loss: 0.5255\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4981 - val_loss: 0.5253\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4979 - val_loss: 0.5251\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.5420\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 7.2476 - val_loss: 5.6624\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.8656 - val_loss: 3.9074\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.3920 - val_loss: 2.7963\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.4565 - val_loss: 2.0775\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.8509 - val_loss: 1.6037\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.4525 - val_loss: 1.2874\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1872 - val_loss: 1.0735\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0082 - val_loss: 0.9272\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8864 - val_loss: 0.8266\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8026 - val_loss: 0.7563\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7443 - val_loss: 0.7068\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7031 - val_loss: 0.6713\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6735 - val_loss: 0.6456\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6519 - val_loss: 0.6268\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6359 - val_loss: 0.6126\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6236 - val_loss: 0.6018\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6140 - val_loss: 0.5933\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6064 - val_loss: 0.5865\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6001 - val_loss: 0.5810\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5948 - val_loss: 0.5764\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5902 - val_loss: 0.5725\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5862 - val_loss: 0.5691\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5826 - val_loss: 0.5661\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5793 - val_loss: 0.5634\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5764 - val_loss: 0.5610\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5736 - val_loss: 0.5588\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5710 - val_loss: 0.5568\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5686 - val_loss: 0.5549\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5663 - val_loss: 0.5531\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5642 - val_loss: 0.5515\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5622 - val_loss: 0.5500\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5602 - val_loss: 0.5486\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5584 - val_loss: 0.5472\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5566 - val_loss: 0.5459\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5550 - val_loss: 0.5447\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5534 - val_loss: 0.5436\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5518 - val_loss: 0.5425\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5504 - val_loss: 0.5414\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5490 - val_loss: 0.5405\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5476 - val_loss: 0.5395\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5463 - val_loss: 0.5386\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5451 - val_loss: 0.5378\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5439 - val_loss: 0.5370\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5428 - val_loss: 0.5362\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5417 - val_loss: 0.5355\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5407 - val_loss: 0.5349\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5397 - val_loss: 0.5342\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5388 - val_loss: 0.5335\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5379 - val_loss: 0.5329\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5370 - val_loss: 0.5324\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5362 - val_loss: 0.5318\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5354 - val_loss: 0.5313\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5346 - val_loss: 0.5308\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5339 - val_loss: 0.5304\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5332 - val_loss: 0.5299\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5325 - val_loss: 0.5295\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5319 - val_loss: 0.5291\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5313 - val_loss: 0.5287\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5307 - val_loss: 0.5283\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5301 - val_loss: 0.5279\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5296 - val_loss: 0.5276\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5291 - val_loss: 0.5273\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5286 - val_loss: 0.5270\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5281 - val_loss: 0.5267\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5276 - val_loss: 0.5265\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5272 - val_loss: 0.5262\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5268 - val_loss: 0.5259\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5264 - val_loss: 0.5257\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5260 - val_loss: 0.5255\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5256 - val_loss: 0.5253\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5253 - val_loss: 0.5251\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5249 - val_loss: 0.5249\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5246 - val_loss: 0.5247\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 0.5245\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5240 - val_loss: 0.5243\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 0.5242\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 0.5241\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5232 - val_loss: 0.5239\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5229 - val_loss: 0.5237\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5227 - val_loss: 0.5236\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5225 - val_loss: 0.5235\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5223 - val_loss: 0.5233\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5220 - val_loss: 0.5232\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5218 - val_loss: 0.5231\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5216 - val_loss: 0.5230\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5214 - val_loss: 0.5230\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5213 - val_loss: 0.5228\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5211 - val_loss: 0.5228\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5209 - val_loss: 0.5226\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5208 - val_loss: 0.5225\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5206 - val_loss: 0.5224\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5205 - val_loss: 0.5224\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5203 - val_loss: 0.5223\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5202 - val_loss: 0.5222\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5201 - val_loss: 0.5222\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5199 - val_loss: 0.5221\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5198 - val_loss: 0.5221\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5197 - val_loss: 0.5220\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5196 - val_loss: 0.5220\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5195 - val_loss: 0.5219\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4916\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 3.1490 - val_loss: 1.0772\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8716 - val_loss: 0.6616\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6422 - val_loss: 0.6191\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6027 - val_loss: 0.5956\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5828 - val_loss: 0.5810\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5669 - val_loss: 0.5692\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5554 - val_loss: 0.5616\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5465 - val_loss: 0.5532\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5393 - val_loss: 0.5480\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5340 - val_loss: 0.5439\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5297 - val_loss: 0.5419\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5265 - val_loss: 0.5381\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5238 - val_loss: 0.5379\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5216 - val_loss: 0.5333\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5199 - val_loss: 0.5312\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5183 - val_loss: 0.5289\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5171 - val_loss: 0.5295\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5162 - val_loss: 0.5292\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5158 - val_loss: 0.5281\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5144 - val_loss: 0.5281\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5145 - val_loss: 0.5259\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5138 - val_loss: 0.5253\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5134 - val_loss: 0.5284\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5131 - val_loss: 0.5274\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5131 - val_loss: 0.5251\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5129 - val_loss: 0.5247\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5122 - val_loss: 0.5257\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5122 - val_loss: 0.5235\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5123 - val_loss: 0.5238\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5116 - val_loss: 0.5234\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5118 - val_loss: 0.5248\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5111 - val_loss: 0.5253\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5117 - val_loss: 0.5231\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5116 - val_loss: 0.5233\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5112 - val_loss: 0.5218\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5111 - val_loss: 0.5254\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5109 - val_loss: 0.5247\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5116 - val_loss: 0.5224\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5114 - val_loss: 0.5245\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5115 - val_loss: 0.5211\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5110 - val_loss: 0.5214\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5114 - val_loss: 0.5228\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5112 - val_loss: 0.5212\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5116 - val_loss: 0.5210\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5112 - val_loss: 0.5209\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5116 - val_loss: 0.5222\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5109 - val_loss: 0.5205\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5116 - val_loss: 0.5218\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5115 - val_loss: 0.5213\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5110 - val_loss: 0.5207\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5111 - val_loss: 0.5209\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5113 - val_loss: 0.5206\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5112 - val_loss: 0.5212\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5112 - val_loss: 0.5212\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5104 - val_loss: 0.5241\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5111 - val_loss: 0.5222\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5108 - val_loss: 0.5236\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5012\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 2.9233 - val_loss: 1.0743\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8156 - val_loss: 0.6795\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6475 - val_loss: 0.6189\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6006 - val_loss: 0.5908\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5730 - val_loss: 0.5733\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5535 - val_loss: 0.5601\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5388 - val_loss: 0.5510\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5278 - val_loss: 0.5449\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5194 - val_loss: 0.5394\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5135 - val_loss: 0.5350\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5086 - val_loss: 0.5321\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5052 - val_loss: 0.5303\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5026 - val_loss: 0.5275\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5004 - val_loss: 0.5265\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4988 - val_loss: 0.5252\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4980 - val_loss: 0.5253\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4970 - val_loss: 0.5239\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4963 - val_loss: 0.5245\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4958 - val_loss: 0.5241\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4954 - val_loss: 0.5228\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4948 - val_loss: 0.5248\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4949 - val_loss: 0.5226\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4944 - val_loss: 0.5242\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4939 - val_loss: 0.5218\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4946 - val_loss: 0.5232\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4941 - val_loss: 0.5230\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4940 - val_loss: 0.5217\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4939 - val_loss: 0.5219\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4938 - val_loss: 0.5224\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4939 - val_loss: 0.5218\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4938 - val_loss: 0.5226\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4938 - val_loss: 0.5229\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4938 - val_loss: 0.5217\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4937 - val_loss: 0.5219\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4937 - val_loss: 0.5215\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4936 - val_loss: 0.5224\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4936 - val_loss: 0.5210\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4937 - val_loss: 0.5217\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4931 - val_loss: 0.5233\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4940 - val_loss: 0.5218\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4935 - val_loss: 0.5211\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4936 - val_loss: 0.5202\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4937 - val_loss: 0.5221\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4936 - val_loss: 0.5213\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4936 - val_loss: 0.5222\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4934 - val_loss: 0.5215\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4935 - val_loss: 0.5214\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4936 - val_loss: 0.5216\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4936 - val_loss: 0.5205\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4933 - val_loss: 0.5210\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4935 - val_loss: 0.5224\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4936 - val_loss: 0.5229\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5362\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 2.9173 - val_loss: 1.0926\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7820 - val_loss: 0.6860\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6345 - val_loss: 0.6152\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5982 - val_loss: 0.5857\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5783 - val_loss: 0.5698\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5647 - val_loss: 0.5596\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5547 - val_loss: 0.5526\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5474 - val_loss: 0.5481\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5420 - val_loss: 0.5428\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5378 - val_loss: 0.5396\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5345 - val_loss: 0.5376\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5316 - val_loss: 0.5336\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5292 - val_loss: 0.5314\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5276 - val_loss: 0.5313\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5260 - val_loss: 0.5321\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5251 - val_loss: 0.5300\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5237 - val_loss: 0.5279\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5224 - val_loss: 0.5304\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5226 - val_loss: 0.5260\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5218 - val_loss: 0.5254\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5213 - val_loss: 0.5245\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5212 - val_loss: 0.5241\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5205 - val_loss: 0.5247\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5201 - val_loss: 0.5229\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5201 - val_loss: 0.5236\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5198 - val_loss: 0.5228\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5189 - val_loss: 0.5220\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5192 - val_loss: 0.5242\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5193 - val_loss: 0.5242\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5194 - val_loss: 0.5230\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5191 - val_loss: 0.5224\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5187 - val_loss: 0.5222\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5187 - val_loss: 0.5226\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5187 - val_loss: 0.5233\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5184 - val_loss: 0.5214\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5187 - val_loss: 0.5228\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5187 - val_loss: 0.5231\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5181 - val_loss: 0.5220\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5183 - val_loss: 0.5211\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5182 - val_loss: 0.5206\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5186 - val_loss: 0.5216\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5184 - val_loss: 0.5223\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5185 - val_loss: 0.5209\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5181 - val_loss: 0.5197\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5179 - val_loss: 0.5201\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5183 - val_loss: 0.5202\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5179 - val_loss: 0.5214\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5184 - val_loss: 0.5213\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5177 - val_loss: 0.5187\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5182 - val_loss: 0.5208\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5181 - val_loss: 0.5210\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5181 - val_loss: 0.5199\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5180 - val_loss: 0.5200\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5182 - val_loss: 0.5202\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5181 - val_loss: 0.5219\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5184 - val_loss: 0.5209\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5179 - val_loss: 0.5219\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5183 - val_loss: 0.5199\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5179 - val_loss: 0.5210\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4878\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0819 - val_loss: 5.7795\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 6.4528 - val_loss: 607.8739\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 824.7357 - val_loss: 87953.8203\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 170304.1094 - val_loss: 12876086.0000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 21892864.0000 - val_loss: 1891212928.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 5015279616.0000 - val_loss: 278624763904.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 6336286818304.0000 - val_loss: 42838641344512.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 991419246313472.0000 - val_loss: 6079581505191936.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 170848748153339904.0000 - val_loss: 913363690718232576.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2306548895678726144.0000 - val_loss: 136344464413339680768.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 219243814847185420288.0000 - val_loss: 20140392519376450879488.0000\n",
      "121/121 [==============================] - 0s 3ms/step - loss: 10133953719612909551616.0000\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 4ms/step - loss: 55.7688 - val_loss: 281.6794\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 15821.0820 - val_loss: 167413.5000\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 968840.8125 - val_loss: 100086984.0000\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4500784640.0000 - val_loss: 60461408256.0000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 5822534909952.0000 - val_loss: 36397104758784.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3453811909722112.0000 - val_loss: 22268031040225280.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 219165274807468032.0000 - val_loss: 13175020125616603136.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 554012946988888227840.0000 - val_loss: 8020585551273775857664.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 542257030026252158763008.0000 - val_loss: 4808647381279531669127168.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 208497257925409926958546944.0000 - val_loss: 2849016685623084848947134464.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 185937570091610631150766129152.0000 - val_loss: 1840265266012161294214038028288.0000\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 12251927193198460980915339264.0000\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8056 - val_loss: 0.5588\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5467 - val_loss: 0.5568\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5276 - val_loss: 0.5637\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5502 - val_loss: 0.6831\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5429 - val_loss: 0.9914\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6894 - val_loss: 3.4106\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1621 - val_loss: 10.2978\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.9379 - val_loss: 39.1308\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 9.5939 - val_loss: 130.8551\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 31.4311 - val_loss: 470.0372\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 119.0616 - val_loss: 1607.7238\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 361.2646 - val_loss: 5648.0376\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 14044.8535\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 6.0589 - val_loss: 3.8622\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.9012 - val_loss: 2.2567\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.8310 - val_loss: 1.6018\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3661 - val_loss: 1.2646\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1075 - val_loss: 1.0492\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9391 - val_loss: 0.9054\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8325 - val_loss: 0.8113\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7656 - val_loss: 0.7502\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7247 - val_loss: 0.7114\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6991 - val_loss: 0.6864\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6823 - val_loss: 0.6694\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6708 - val_loss: 0.6575\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6624 - val_loss: 0.6494\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6555 - val_loss: 0.6426\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6495 - val_loss: 0.6363\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6442 - val_loss: 0.6311\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6391 - val_loss: 0.6258\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6345 - val_loss: 0.6215\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6301 - val_loss: 0.6171\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6257 - val_loss: 0.6124\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6218 - val_loss: 0.6084\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6178 - val_loss: 0.6049\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6139 - val_loss: 0.6007\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6102 - val_loss: 0.5969\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6066 - val_loss: 0.5936\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6031 - val_loss: 0.5904\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5996 - val_loss: 0.5872\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5962 - val_loss: 0.5834\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5929 - val_loss: 0.5799\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5899 - val_loss: 0.5772\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5868 - val_loss: 0.5747\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5837 - val_loss: 0.5712\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5808 - val_loss: 0.5688\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5780 - val_loss: 0.5663\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5752 - val_loss: 0.5640\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5724 - val_loss: 0.5608\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5697 - val_loss: 0.5583\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5671 - val_loss: 0.5565\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5646 - val_loss: 0.5540\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5620 - val_loss: 0.5513\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5596 - val_loss: 0.5495\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5571 - val_loss: 0.5469\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5548 - val_loss: 0.5453\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5525 - val_loss: 0.5430\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5503 - val_loss: 0.5410\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5480 - val_loss: 0.5391\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5458 - val_loss: 0.5374\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5437 - val_loss: 0.5353\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5415 - val_loss: 0.5328\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5396 - val_loss: 0.5316\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5374 - val_loss: 0.5292\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5355 - val_loss: 0.5279\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5336 - val_loss: 0.5265\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5316 - val_loss: 0.5253\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5298 - val_loss: 0.5225\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5280 - val_loss: 0.5210\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5261 - val_loss: 0.5192\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5244 - val_loss: 0.5174\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5227 - val_loss: 0.5158\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5209 - val_loss: 0.5145\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5193 - val_loss: 0.5134\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5175 - val_loss: 0.5125\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5159 - val_loss: 0.5106\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5144 - val_loss: 0.5094\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5127 - val_loss: 0.5075\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5112 - val_loss: 0.5065\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5096 - val_loss: 0.5053\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5082 - val_loss: 0.5037\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5068 - val_loss: 0.5029\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5053 - val_loss: 0.5018\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5039 - val_loss: 0.5010\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5026 - val_loss: 0.4996\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5013 - val_loss: 0.4983\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4998 - val_loss: 0.4972\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4986 - val_loss: 0.4959\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4974 - val_loss: 0.4947\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4961 - val_loss: 0.4935\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4950 - val_loss: 0.4926\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4937 - val_loss: 0.4916\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4927 - val_loss: 0.4905\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4916 - val_loss: 0.4900\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4906 - val_loss: 0.4886\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4895 - val_loss: 0.4879\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4885 - val_loss: 0.4871\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4875 - val_loss: 0.4861\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4866 - val_loss: 0.4851\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4856 - val_loss: 0.4838\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4847 - val_loss: 0.4829\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4838 - val_loss: 0.4818\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4829 - val_loss: 0.4814\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4821 - val_loss: 0.4802\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4811 - val_loss: 0.4796\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4804 - val_loss: 0.4784\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4795 - val_loss: 0.4775\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4788 - val_loss: 0.4771\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4780 - val_loss: 0.4756\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4773 - val_loss: 0.4749\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4765 - val_loss: 0.4753\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4759 - val_loss: 0.4734\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4752 - val_loss: 0.4730\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4598\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 4.3180 - val_loss: 2.9730\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.2374 - val_loss: 1.6731\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.4121 - val_loss: 1.2429\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1400 - val_loss: 1.0857\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0183 - val_loss: 0.9902\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9373 - val_loss: 0.9170\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8740 - val_loss: 0.8566\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8226 - val_loss: 0.8072\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7806 - val_loss: 0.7661\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7460 - val_loss: 0.7325\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7180 - val_loss: 0.7053\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6955 - val_loss: 0.6834\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6775 - val_loss: 0.6654\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6628 - val_loss: 0.6510\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6509 - val_loss: 0.6390\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6409 - val_loss: 0.6292\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6325 - val_loss: 0.6210\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6252 - val_loss: 0.6136\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6188 - val_loss: 0.6072\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6130 - val_loss: 0.6014\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6077 - val_loss: 0.5961\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6027 - val_loss: 0.5913\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5980 - val_loss: 0.5867\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5935 - val_loss: 0.5821\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5891 - val_loss: 0.5778\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5849 - val_loss: 0.5736\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5807 - val_loss: 0.5697\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5767 - val_loss: 0.5657\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5727 - val_loss: 0.5619\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5688 - val_loss: 0.5582\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5649 - val_loss: 0.5545\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5611 - val_loss: 0.5510\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5573 - val_loss: 0.5476\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5535 - val_loss: 0.5442\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5499 - val_loss: 0.5408\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5463 - val_loss: 0.5376\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5428 - val_loss: 0.5344\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5393 - val_loss: 0.5312\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5359 - val_loss: 0.5281\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5326 - val_loss: 0.5251\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5293 - val_loss: 0.5221\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5260 - val_loss: 0.5192\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5228 - val_loss: 0.5163\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5197 - val_loss: 0.5134\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5166 - val_loss: 0.5107\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5136 - val_loss: 0.5080\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5106 - val_loss: 0.5054\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5078 - val_loss: 0.5029\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5049 - val_loss: 0.5003\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5021 - val_loss: 0.4979\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4994 - val_loss: 0.4954\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4966 - val_loss: 0.4931\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4939 - val_loss: 0.4907\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4912 - val_loss: 0.4884\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4886 - val_loss: 0.4859\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4861 - val_loss: 0.4837\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4837 - val_loss: 0.4815\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4812 - val_loss: 0.4795\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4789 - val_loss: 0.4773\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4766 - val_loss: 0.4752\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4743 - val_loss: 0.4733\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4720 - val_loss: 0.4712\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4698 - val_loss: 0.4695\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4677 - val_loss: 0.4677\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4657 - val_loss: 0.4659\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4637 - val_loss: 0.4642\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4617 - val_loss: 0.4625\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4599 - val_loss: 0.4607\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4582 - val_loss: 0.4594\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4564 - val_loss: 0.4580\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4548 - val_loss: 0.4567\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4532 - val_loss: 0.4553\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4516 - val_loss: 0.4541\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4502 - val_loss: 0.4528\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4487 - val_loss: 0.4514\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4473 - val_loss: 0.4504\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4460 - val_loss: 0.4491\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4447 - val_loss: 0.4479\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4435 - val_loss: 0.4471\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4422 - val_loss: 0.4460\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4412 - val_loss: 0.4450\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4400 - val_loss: 0.4440\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4389 - val_loss: 0.4433\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4379 - val_loss: 0.4426\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4369 - val_loss: 0.4414\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.4361 - val_loss: 0.4409\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4352 - val_loss: 0.4401\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4344 - val_loss: 0.4391\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4337 - val_loss: 0.4387\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4329 - val_loss: 0.4378\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4322 - val_loss: 0.4371\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4315 - val_loss: 0.4369\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4309 - val_loss: 0.4359\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4302 - val_loss: 0.4358\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4297 - val_loss: 0.4355\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4291 - val_loss: 0.4347\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4286 - val_loss: 0.4343\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4280 - val_loss: 0.4338\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4275 - val_loss: 0.4331\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4270 - val_loss: 0.4325\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4746\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dujapc/ml/ml_env/lib/python3.10/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 4ms/step - loss: 4.6576 - val_loss: 3.4665\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 2.7952 - val_loss: 2.1667\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.7950 - val_loss: 1.4854\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3054 - val_loss: 1.1948\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1076 - val_loss: 1.0757\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0241 - val_loss: 1.0103\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9757 - val_loss: 0.9643\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.9417 - val_loss: 0.9284\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9158 - val_loss: 0.8996\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8954 - val_loss: 0.8742\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8781 - val_loss: 0.8536\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8638 - val_loss: 0.8366\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8517 - val_loss: 0.8219\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8412 - val_loss: 0.8093\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8317 - val_loss: 0.7982\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8230 - val_loss: 0.7883\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8151 - val_loss: 0.7793\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8076 - val_loss: 0.7711\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8008 - val_loss: 0.7639\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7941 - val_loss: 0.7568\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7880 - val_loss: 0.7506\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7820 - val_loss: 0.7445\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7765 - val_loss: 0.7390\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7711 - val_loss: 0.7338\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7659 - val_loss: 0.7287\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7610 - val_loss: 0.7240\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7563 - val_loss: 0.7194\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7518 - val_loss: 0.7150\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7474 - val_loss: 0.7109\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7432 - val_loss: 0.7068\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7392 - val_loss: 0.7029\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7353 - val_loss: 0.6992\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7314 - val_loss: 0.6956\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7277 - val_loss: 0.6922\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7241 - val_loss: 0.6888\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7206 - val_loss: 0.6855\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7171 - val_loss: 0.6824\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7138 - val_loss: 0.6792\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7106 - val_loss: 0.6761\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7074 - val_loss: 0.6732\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7043 - val_loss: 0.6703\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7013 - val_loss: 0.6674\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6983 - val_loss: 0.6646\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6954 - val_loss: 0.6619\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6925 - val_loss: 0.6593\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6898 - val_loss: 0.6568\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6871 - val_loss: 0.6542\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6844 - val_loss: 0.6517\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6818 - val_loss: 0.6493\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6793 - val_loss: 0.6470\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6767 - val_loss: 0.6446\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6743 - val_loss: 0.6423\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6719 - val_loss: 0.6400\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6694 - val_loss: 0.6378\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6671 - val_loss: 0.6356\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6649 - val_loss: 0.6335\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6626 - val_loss: 0.6315\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6604 - val_loss: 0.6294\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6582 - val_loss: 0.6274\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6560 - val_loss: 0.6254\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6539 - val_loss: 0.6235\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6517 - val_loss: 0.6215\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6497 - val_loss: 0.6197\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6477 - val_loss: 0.6178\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6457 - val_loss: 0.6159\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6437 - val_loss: 0.6141\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6417 - val_loss: 0.6123\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6398 - val_loss: 0.6107\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6378 - val_loss: 0.6089\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6360 - val_loss: 0.6071\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6341 - val_loss: 0.6054\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6322 - val_loss: 0.6037\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6303 - val_loss: 0.6022\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6286 - val_loss: 0.6004\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6268 - val_loss: 0.5987\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6250 - val_loss: 0.5971\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6232 - val_loss: 0.5955\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6215 - val_loss: 0.5939\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6197 - val_loss: 0.5922\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6180 - val_loss: 0.5907\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6163 - val_loss: 0.5891\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6145 - val_loss: 0.5873\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6127 - val_loss: 0.5856\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6108 - val_loss: 0.5839\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6090 - val_loss: 0.5820\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6071 - val_loss: 0.5802\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6051 - val_loss: 0.5784\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6033 - val_loss: 0.5767\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.6015 - val_loss: 0.5750\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5996 - val_loss: 0.5734\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5977 - val_loss: 0.5717\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5961 - val_loss: 0.5702\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5944 - val_loss: 0.5687\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5926 - val_loss: 0.5671\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5909 - val_loss: 0.5658\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5893 - val_loss: 0.5641\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5875 - val_loss: 0.5629\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5860 - val_loss: 0.5614\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.5844 - val_loss: 0.5600\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5827 - val_loss: 0.5586\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5609\n",
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7840 - val_loss: 0.5674\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4812 - val_loss: 0.5003\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4470 - val_loss: 0.4443\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4263 - val_loss: 0.4257\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4098 - val_loss: 0.4005\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3983 - val_loss: 0.4096\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3894 - val_loss: 0.3823\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3820 - val_loss: 0.3809\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3726 - val_loss: 0.3755\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3651 - val_loss: 0.3808\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3576 - val_loss: 0.3822\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3555 - val_loss: 0.4004\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3480 - val_loss: 0.4020\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3392 - val_loss: 0.4432\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3456 - val_loss: 0.4913\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3296 - val_loss: 0.4668\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3324 - val_loss: 0.4633\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3241 - val_loss: 0.6163\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3210 - val_loss: 0.4764\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 2.3582\n"
     ]
    }
   ],
   "source": [
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "              validation_data=(X_valid, y_valid),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = rnd_search_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.334478755791982"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eed8ddd848e855132c535757d23bf43dc6b9b25110162aa7f159b14175251349"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('ml_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
